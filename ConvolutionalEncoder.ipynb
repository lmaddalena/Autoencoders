{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional autoencoder for removing noise from images\n",
    "### Ref. Deep Learning with TensorFlow 2 and Keras ch.9"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "np.random.seed(11)\n",
    "tf.random.set_seed(11)\n",
    "batch_size = 128\n",
    "max_epochs = 50\n",
    "filters = [32, 32, 16]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the MNIST dataset, normalize it, and introduce noise in it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "(x_train, _), (x_test, _) = K.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "noise = 0.5\n",
    "x_train_noisy = x_train + noise * np.random.normal(loc= 0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise * np.random.normal(loc= 0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0, 1)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0, 1)\n",
    "\n",
    "x_train_noisy = x_train_noisy.astype('float32')\n",
    "x_test_noisy = x_test_noisy.astype('float32')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Encoder(K.layers.Layer):\n",
    "    def __init__(self, filters) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = Conv2D(filters = filters[0], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv2 = Conv2D(filters = filters[1], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv3 = Conv2D(filters = filters[2], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.pool = MaxPooling2D((2, 2), padding='same')\n",
    "\n",
    "    def call(self, input_features):\n",
    "        x = self.conv1(input_features)\n",
    "        #print(\"Ex1\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(\"Ex2\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Decoder(K.layers.Layer):\n",
    "    def __init__(self, filters) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv1 = Conv2D(filters = filters[2], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv2 = Conv2D(filters = filters[1], kernel_size=3, strides=1, activation='relu', padding='same')\n",
    "        self.conv3 = Conv2D(filters = filters[0], kernel_size=3, strides=1, activation='relu', padding='valid')\n",
    "        self.conv4 = Conv2D(1, 3, 1, activation='sigmoid', padding='same')\n",
    "        self.upsample = UpSampling2D((2,2))\n",
    "    \n",
    "    def call(self, encoded):\n",
    "        x = self.conv1(encoded)\n",
    "        #print(\"Dx1\", x.shape)\n",
    "        x = self.upsample(x)\n",
    "        #print(\"Dx2\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Autoencoder(K.Model):\n",
    "    def __init__(self, filters) -> None:\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(filters)\n",
    "        self.decoder = Decoder(filters)\n",
    "    \n",
    "    def call(self, input_features):\n",
    "        encoded = self.encoder(input_features)\n",
    "        reconstructed = self.decoder(encoded)\n",
    "        return reconstructed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = Autoencoder(filters)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "loss = model.fit(\n",
    "    x_train_noisy,    \n",
    "    x_train,\n",
    "    validation_data = (x_test_noisy, x_test),\n",
    "    epochs=max_epochs,\n",
    "    batch_size=batch_size\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 80s 169ms/step - loss: 0.2048 - val_loss: 0.1504\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 78s 166ms/step - loss: 0.1420 - val_loss: 0.1324\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 77s 165ms/step - loss: 0.1289 - val_loss: 0.1247\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.1221 - val_loss: 0.1197\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.1179 - val_loss: 0.1152\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.1149 - val_loss: 0.1137\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.1126 - val_loss: 0.1108\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.1111 - val_loss: 0.1096\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.1097 - val_loss: 0.1082\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 73s 157ms/step - loss: 0.1085 - val_loss: 0.1078\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.1075 - val_loss: 0.1062\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.1067 - val_loss: 0.1058\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.1060 - val_loss: 0.1057\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.1054 - val_loss: 0.1047\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.1049 - val_loss: 0.1037\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.1043 - val_loss: 0.1044\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 73s 157ms/step - loss: 0.1038 - val_loss: 0.1030\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.1033 - val_loss: 0.1027\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1030 - val_loss: 0.1019\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.1026 - val_loss: 0.1020\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1023 - val_loss: 0.1015\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1021 - val_loss: 0.1020\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.1018 - val_loss: 0.1016\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1016 - val_loss: 0.1009\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 72s 155ms/step - loss: 0.1014 - val_loss: 0.1011\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1011 - val_loss: 0.1011\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1009 - val_loss: 0.1007\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.1008 - val_loss: 0.1005\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.1007 - val_loss: 0.1001\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1005 - val_loss: 0.1001\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.1004 - val_loss: 0.1004\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1002 - val_loss: 0.1005\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.1000 - val_loss: 0.0996\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0999 - val_loss: 0.0996\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 72s 155ms/step - loss: 0.0999 - val_loss: 0.0998\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0997 - val_loss: 0.0994\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0996 - val_loss: 0.0993\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0996 - val_loss: 0.0990\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0994 - val_loss: 0.0988\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 140s 300ms/step - loss: 0.0994 - val_loss: 0.0993\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 383s 818ms/step - loss: 0.0993 - val_loss: 0.0989\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 383s 816ms/step - loss: 0.0992 - val_loss: 0.0988\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 161s 342ms/step - loss: 0.0991 - val_loss: 0.0988\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 354s 756ms/step - loss: 0.0990 - val_loss: 0.0988\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 382s 815ms/step - loss: 0.0990 - val_loss: 0.0989\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 383s 817ms/step - loss: 0.0990 - val_loss: 0.0988\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 382s 815ms/step - loss: 0.0989 - val_loss: 0.0988\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 380s 810ms/step - loss: 0.0988 - val_loss: 0.0986\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 382s 815ms/step - loss: 0.0987 - val_loss: 0.0991\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 381s 812ms/step - loss: 0.0987 - val_loss: 0.0988\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "plt.plot(range(max_epochs), loss.history['loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "number = 10 # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for index in range(number):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, number, index + 1)\n",
    "    plt.imshow(x_test_noisy[index].reshape(28,28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, number, index + 1 + number)\n",
    "    plt.imshow(model(x_test_noisy)[index].numpy().reshape(28,28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)    "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,28,28,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2D]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e1cd7d0f82c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# display reconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-01e7f4caa407>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreconstructed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f0d0073b104f>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print(\"Ex1\", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1017\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2601\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2603\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2604\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2605\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    937\u001b[0m           \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m           data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    940\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1024\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[1;32m   1025\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1026\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1027\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/venvML/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,28,28,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2D]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('venvML': venv)"
  },
  "interpreter": {
   "hash": "61e27811106b0eff094ccf4c65f60fdc343a4cd46af11344d5f306dadca4da6f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}